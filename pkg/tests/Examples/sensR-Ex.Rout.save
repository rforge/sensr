
R version 3.0.0 (2013-04-03) -- "Masked Marvel"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "sensR"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('sensR')
Loading required package: ordinal
Loading required package: MASS
Loading required package: ucminf
Loading required package: Matrix
Loading required package: lattice
Loading required package: numDeriv
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("AUC")
> ### * AUC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: AUC
> ### Title: AUC computation
> ### Aliases: AUC.default AUC.anota print.AUC AUC
> ### Keywords: htest
> 
> ### ** Examples
> 
> (odor <- matrix(c(112, 112, 72, 53, 22, 4, 7, 38, 50, 117, 101, 62), 2,
+                byrow = TRUE))
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]  112  112   72   53   22    4
[2,]    7   38   50  117  101   62
> (d.primes <- SDT(odor)[,3])
       1        2        3        4        5 
1.553861 1.421438 1.468147 1.316269 1.329261 
> for(i in 1:5) print(AUC(d.primes[i]))
AUC: 0.8640605 
AUC: 0.8425777 
AUC: 0.8503969 
AUC: 0.8240067 
AUC: 0.8263731 
> ## Provide standard error of d-prime and compute CI:
> fm1 <- AnotA(8, 25, 1, 25)
> AUC(fm1$coef, fm1$se)
AUC: 0.8178519 
0.95% CI: [0.5716444, 0.9488555] 
> AUC(fm1)
AUC: 0.8720794 
> 
> 
> 
> cleanEx()
> nameEx("AnotA")
> ### * AnotA
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: AnotA
> ### Title: Analysis of A-not-A tests
> ### Aliases: AnotA confint.anota plot.anota
> ### Keywords: models
> 
> ### ** Examples
> 
> # data: 10 of the A-samples were judged to be A
> #       20 A-samples in total
> #       3 of the not-A samples were judged to be A
> #       20 not-A-samples in total
> 
> AnotA(10, 20, 3, 20)

Call:  AnotA(x1 = 10, n1 = 20, x2 = 3, n2 = 20) 

Results for the A-Not A test:

        Estimate Std. Error     Lower    Upper   P-value
d-prime 1.036433  0.4425006 0.1691481 1.903719 0.0203712
> (m1 <- AnotA(10, 20, 3, 20))

Call:  AnotA(x1 = 10, n1 = 20, x2 = 3, n2 = 20) 

Results for the A-Not A test:

        Estimate Std. Error     Lower    Upper   P-value
d-prime 1.036433  0.4425006 0.1691481 1.903719 0.0203712
> 
> ## plot distributions of sensory intensity:
> plot(m1)
> 
> ## likelihood based confidence intervals:
> confint(m1)
Waiting for profiling to be done...
               2.5 %    97.5 %
threshold -0.5505227 0.5505227
d.prime    1.9331334 0.1900176
> 
> ## Extended example plotting the profile likelihood
> xt <- cbind(c(3, 10), c(20 - 3, 20 - 10))
> lev <- gl(2, 1)
> summary(res <- glm(xt ~ lev,
+                    family = binomial(link = probit)))

Call:
glm(formula = xt ~ lev, family = binomial(link = probit))

Deviance Residuals: 
[1]  0  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)  -1.0364     0.3424  -3.027  0.00247 **
lev2          1.0364     0.4425   2.342  0.01917 * 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 5.8122e+00  on 1  degrees of freedom
Residual deviance: 3.1086e-15  on 0  degrees of freedom
AIC: 10.303

Number of Fisher Scoring iterations: 3

> N <- 100
> dev <- double(N)
> level <- c(0.95, 0.99)
> delta <- seq(1e-4, 5, length = N)
> for(i in 1:N)
+   dev[i] <- glm(xt ~ 1 + offset(c(0, delta[i])),
+                 family = binomial(probit))$deviance
> plot(delta, exp(-dev/2), type = "l",
+      xlab = expression(delta),
+      ylab = "Normalized Profile Likelihood")
> ## Add Normal approximation:
> lines(delta, exp(-(delta - coef(res)[2])^2 /
+                  (2 * vcov(res)[2,2])), lty = 2)
> ## Add confidence limits:
> lim <- sapply(level, function(x)
+               exp(-qchisq(x, df=1)/2) )
> abline(h = lim, col = "grey")
> 
> 
> 
> 
> cleanEx()
> nameEx("ROC")
> ### * ROC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ROC
> ### Title: Plot the Receiver Operating Characteristic Curve
> ### Aliases: ROC.default ROC.anota ROC
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## ROC.default:
> (mat <- matrix(c(8, 17, 1, 24), 2, byrow = TRUE))
     [,1] [,2]
[1,]    8   17
[2,]    1   24
> (d.prime <- SDT(mat, "probit")[3])
[1] 1.282987
> ROC(d.prime)
> ## ROC.anota:
> fm1 <- AnotA(8, 25, 1, 25)
> ROC(fm1)
> 
> 
> 
> cleanEx()
> nameEx("SDT")
> ### * SDT
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SDT
> ### Title: Signal Detection Theory Computation of d-prime
> ### Aliases: SDT
> ### Keywords: models
> 
> ### ** Examples
> 
> ### Design table:
> ## 8  "yes"-responses to yes-samples
> ## 1  "yes"-responses to no-samples
> ## 17 "no"-response to yes-samples
> ## 24 "no"-responses to no-samples
> ## Note that response-class is columnwise and true-class is rowwise:
> (mat <- rbind(c(8, 17),
+               c(1, 24)))
     [,1] [,2]
[1,]    8   17
[2,]    1   24
> SDT(mat, "logit")
  z(Hit rate) z(False alarm rate)  d-prime
1  -0.7537718           -3.178054 2.424282
> SDT(mat, "probit")
  z(Hit rate) z(False alarm rate)  d-prime
1  -0.4676988           -1.750686 1.282987
> 
> ## compare to AnotA():
> AnotA(8, 25, 1, 25)

Call:  AnotA(x1 = 8, n1 = 25, x2 = 1, n2 = 25) 

Results for the A-Not A test:

        Estimate Std. Error     Lower    Upper    P-value
d-prime 1.282987  0.5243127 0.2553532 2.310621 0.01160771
> 
> ## Compute d-prime 'by hand':
> ## Hit rate and False alarm rates:
> H = 8/(8+17)
> FA = 1/(1+24)
> zH = qnorm(H)
> zFA = qnorm(FA)
> ## d-prime:
> zH - zFA  # d'
[1] 1.282987
> 
> ## Multi-response-class example (odor example from MacMillan and
> ## Creelman, 2005)
> (odor <- matrix(c(112, 112, 72, 53, 22, 4, 7, 38, 50, 117, 101, 62), 2,
+                byrow = TRUE))
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]  112  112   72   53   22    4
[2,]    7   38   50  117  101   62
> obj <- SDT(odor)
> ROC(obj[3,3])
> 
> 
> 
> cleanEx()
> nameEx("betabin")
> ### * betabin
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betabin
> ### Title: Beta-binomial and chance-corrected beta-binomial models for
> ###   over-dispersed binomial data
> ### Aliases: betabin summary.betabin
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Create data:
> x <- c(3,2,6,8,3,4,6,0,9,9,0,2,1,2,8,9,5,7)
> n <- c(10,9,8,9,8,6,9,10,10,10,9,9,10,10,10,10,9,10)
> dat <- data.frame(x, n)
> 
> (bb <- betabin(dat, method = "duotrio"))

Call:
betabin(data = dat, method = "duotrio")

Coefficients:
    mu   gamma  
0.1761  0.5043  

> (bb <- betabin(dat, corrected = FALSE, method = "duotrio"))

Call:
betabin(data = dat, method = "duotrio", corrected = FALSE)

Coefficients:
    mu   gamma  
0.4938  0.3144  

> summary(bb)

Beta-binomial model for the duotrio protocol
with 95 percent confidence intervals

        Estimate Std. Error   Lower   Upper
mu       0.49381    0.07238 0.35195 0.63568
gamma    0.31443    0.08618 0.14551 0.48334
pc       0.50000         NA 0.50000 0.63568
pd       0.00000         NA 0.00000 0.27136
d-prime  0.00000         NA 0.00000 1.33527

log-likelihood:  -41.7087 
LR-test of over-dispersion, G^2: 36.4922 df: 1 p-value: 1.533e-09 
LR-test of association, G^2: 36.5163 df: 2 p-value: 1.177e-08 
> vcov(bb)
              [,1]          [,2]
[1,]  0.0052391046 -0.0003882818
[2,] -0.0003882818  0.0074277876
> logLik(bb)
'log Lik.' -41.70868 (df=2)
> AIC(bb)
[1] 87.41736
> coef(bb)
       mu     gamma 
0.4938123 0.3144258 
> 
> 
> 
> 
> cleanEx()
> nameEx("clls")
> ### * clls
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clls
> ### Title: Cumulative Link Location-Scale Models
> ### Aliases: clls
> ### Keywords: models
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> ## Extend example from polr in package MASS:
> ## Fit model from polr example:
> data(housing, package = "MASS")
> fm1 <- clls(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
Warning in clls(Sat ~ Infl + Type + Cont, weights = Freq, data = housing) :
  This function is no longer supported.
The user is adviced to use clm() from package ordinal instead.
> fm1
Call:
clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq)

Location coefficients:
   InflMedium      InflHigh TypeApartment    TypeAtrium   TypeTerrace 
    0.5663909     1.2888178    -0.5723496    -0.3661848    -1.0910124 
     ContHigh 
    0.3602834 

No Scale coefficients

Intercepts:
 Low|Medium Medium|High 
 -0.4961367   0.6907061 

Residual Deviance: 3479.149 
AIC: 3495.149 
> summary(fm1)

Re-fitting to get Hessian

Warning in clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  :
  This function is no longer supported.
The user is adviced to use clm() from package ordinal instead.
Call:
clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq)

Location coefficients:
              Value   Std. Error z value
InflMedium     0.5664  0.1047     5.4121
InflHigh       1.2888  0.1272    10.1357
TypeApartment -0.5723  0.1192    -4.8001
TypeAtrium    -0.3662  0.1552    -2.3598
TypeTerrace   -1.0910  0.1515    -7.2021
ContHigh       0.3603  0.0955     3.7712

No scale coefficients

Intercepts:
            Value   Std. Error z value
Low|Medium  -0.4961  0.1248    -3.9740
Medium|High  0.6907  0.1255     5.5049

Residual Deviance: 3479.149 
AIC: 3495.149 
> ## With probit link:
> summary(update(fm1, method = "probit"))
Warning in clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  :
  This function is no longer supported.
The user is adviced to use clm() from package ordinal instead.

Re-fitting to get Hessian

Warning in clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  :
  This function is no longer supported.
The user is adviced to use clm() from package ordinal instead.
Call:
clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq, 
    method = "probit")

Location coefficients:
              Value   Std. Error z value
InflMedium     0.3464  0.0641     5.4013
InflHigh       0.7829  0.0764    10.2441
TypeApartment -0.3475  0.0723    -4.8075
TypeAtrium    -0.2179  0.0948    -2.2992
TypeTerrace   -0.6642  0.0918    -7.2350
ContHigh       0.2224  0.0581     3.8262

No scale coefficients

Intercepts:
            Value   Std. Error z value
Low|Medium  -0.2998  0.0762    -3.9371
Medium|High  0.4267  0.0764     5.5850

Residual Deviance: 3479.689 
AIC: 3495.689 
> 
> ## Allow scale to depend on Cont-variable
> summary(fm2 <- update(fm1, scale =~ Cont))
Warning in clls(location = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  :
  This function is no longer supported.
The user is adviced to use clm() from package ordinal instead.

Re-fitting to get Hessian

Warning in clls(location = Sat ~ Infl + Type + Cont, scale = ~Cont, data = housing,  :
  This function is no longer supported.
The user is adviced to use clm() from package ordinal instead.
Call:
clls(location = Sat ~ Infl + Type + Cont, scale = ~Cont, data = housing, 
    weights = Freq)

Location coefficients:
              Value   Std. Error z value
InflMedium     0.5006  0.0965     5.1889
InflHigh       1.1487  0.1287     8.9243
TypeApartment -0.5203  0.1098    -4.7385
TypeAtrium    -0.3469  0.1380    -2.5138
TypeTerrace   -1.0038  0.1403    -7.1557
ContHigh       0.3135  0.0905     3.4656

Scale coefficients:
         Value   Std. Error z value
ContHigh -0.1958  0.0829    -2.3613

Intercepts:
            Value   Std. Error z value
Low|Medium  -0.4581  0.1168    -3.9220
Medium|High  0.6014  0.1219     4.9355

Residual Deviance: 3473.493 
AIC: 3491.493 
> anova(fm1, fm2)
Likelihood ratio tests of cumulative link location-scale models

Response: Sat
                      Model Resid. df Resid. Dev   Test    Df LR stat.
1    Infl + Type + Cont | 1      1673   3479.149                      
2 Infl + Type + Cont | Cont      1672   3473.493 1 vs 2     1 5.655882
     Pr(Chi)
1           
2 0.01739692
> ## which seems to improve the fit
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()
> nameEx("clm2twoAC")
> ### * clm2twoAC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clm2twoAC
> ### Title: Extract 2-AC coefficient table from a cumulative link model
> ### Aliases: clm2twoAC
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Example of a simple 2-AC model. First the conventional way:
> twoAC(c(2, 2, 6))
Results for the 2-AC protocol with data c(2, 2, 6):
        Estimate Std. Error
tau       0.4160     0.2674
d.prime   0.7743     0.5417

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
         Lower Upper
d.prime -0.271 1.859

Significance test:
 Likelihood root statistic = 1.446718 p-value = 0.14798 
 Alternative hypothesis: d-prime is different from 0 
> ## The using a cumulative link model (clm from package ordinal): 
> library(ordinal)
> response <- gl(3,1)
> fit.clm <- clm(response ~ 1, weights = c(2, 2, 6), link = "probit")
> clm2twoAC(fit.clm)
         Estimate Std. Error  z value Pr(>|z|)
tau     0.4159726  0.2674311 1.555439  0.11984
d-prime 0.7742595  0.5416737 1.429384  0.15289
> ## Alternatively we could get estimates and standard errors "by hand":
> tab <- coef(summary(fit.clm))
> theta <- tab[,1]
> (tau <- (theta[2] - theta[1])/sqrt(2))
      2|3 
0.4159726 
> (d.prime <- (-theta[2] - theta[1])/sqrt(2))
      2|3 
0.7742595 
> VCOV <- vcov(fit.clm)
> (se.tau <- sqrt((VCOV[1,1] + VCOV[2,2] - 2*VCOV[2,1])/2))
[1] 0.2674311
> (se.d.prime <- sqrt((VCOV[1,1] + VCOV[2,2] + 2*VCOV[2,1])/2))
[1] 0.5416737
> 
> ## Extended example with a regression model for d.prime
> ## (see the referenced paper for details):
> n.women <- c(2, 2, 6)*10
> n.men <- c(1, 2, 7)*10
> wt <- c(n.women, n.men)
> response <- gl(3,1, length = 6)
> gender <- gl(2, 3, labels = c("women", "men"))
> fm2 <- clm(response ~ gender, weights = wt, link = "probit")
> clm2twoAC(fm2)
           Estimate Std. Error  z value   Pr(>|z|)
tau       0.4670001 0.06700014 6.970135 3.1664e-12
d-prime   0.7898785 0.17021271 4.640538 3.4750e-06
gendermen 0.4533125 0.24627746 1.840658   0.065672
> 
> 
> 
> 
> cleanEx()
> nameEx("confint")
> ### * confint
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: confint.twoAC
> ### Title: Confidence intervals and profile likelihoods for parameters in
> ###   2AC models
> ### Aliases: confint.twoAC confint.profile.twoAC profile.twoAC
> ###   plot.profile.twoAC
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> (fm1 <- twoAC(c(2, 2, 6)))
Results for the 2-AC protocol with data c(2, 2, 6):
        Estimate Std. Error
tau       0.4160     0.2674
d.prime   0.7743     0.5417

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
         Lower Upper
d.prime -0.271 1.859

Significance test:
 Likelihood root statistic = 1.446718 p-value = 0.14798 
 Alternative hypothesis: d-prime is different from 0 
> confint(fm1)
             2.5 %   97.5 %
d.prime -0.2709832 1.859251
> confint(fm1, type = "Wald")
             2.5 %    97.5 %
tau     -0.1081827 0.9401279
d.prime -0.2874014 1.8359205
> 
> pr1 <- profile(fm1)
> confint(pr1)
            2.5 %   97.5 %
d.prime -0.270983 1.859252
> 
> pr1 <- profile(fm1, alpha = 1e-5)
> par(mfrow = c(2,2))
> plot(pr1)
> plot(pr1, Log = FALSE, relative = TRUE)
> plot(pr1, Log = TRUE, relative = TRUE)
> plot(pr1, Log = TRUE, relative = FALSE)
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("discrim")
> ### * discrim
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: discrim
> ### Title: Sensory discrimination analysis
> ### Aliases: discrim print.discrim
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Running the simple discrimination (difference) tests:
> discrim(10, 15, method = "twoAFC")

Estimates for the twoAFC discrimination protocol with 10 correct
answers in 15 trials. One-sided p-value and 95 % two-sided confidence
intervals are based on the 'exact' binomial test. 

        Estimate Std. Error Lower  Upper
pc        0.6667     0.1217   0.5 0.8818
pd        0.3333     0.2434   0.0 0.7635
d-prime   0.6091     0.4734   0.0 1.6742

Result of difference test:
'exact' binomial test:  p-value = 0.1509 
Alternative hypothesis: d-prime is greater than 0 

> discrim(10, 15, method = "threeAFC", statistic = "likelihood")

Estimates for the threeAFC discrimination protocol with 10 correct
answers in 15 trials. One-sided p-value and 95 % two-sided confidence
intervals are based on the likelihood root statistic. 

        Estimate Std. Error  Lower  Upper
pc        0.6667     0.1217 0.4155 0.8652
pd        0.5000     0.1826 0.1232 0.7978
d-prime   1.1159     0.4359 0.2803 1.9967

Result of difference test:
Likelihood Root statistic = 2.632769, p-value: 0.004235
Alternative hypothesis: d-prime is greater than 0 

> discrim(10, 15, method = "duotrio", conf.level = 0.90)

Estimates for the duotrio discrimination protocol with 10 correct
answers in 15 trials. One-sided p-value and 90 % two-sided confidence
intervals are based on the 'exact' binomial test. 

        Estimate Std. Error Lower  Upper
pc        0.6667     0.1217   0.5 0.8583
pd        0.3333     0.2434   0.0 0.7167
d-prime   1.5189     0.7159   0.0 2.8242

Result of difference test:
'exact' binomial test:  p-value = 0.1509 
Alternative hypothesis: d-prime is greater than 0 

> discrim(10, 15, method = "triangle", statistic = "score")

Estimates for the triangle discrimination protocol with 10 correct
answers in 15 trials. One-sided p-value and 95 % two-sided confidence
intervals are based on the Pearson and score statistics. 

        Estimate Std. Error  Lower  Upper
pc        0.6667     0.1217 0.3869 0.8701
pd        0.5000     0.1826 0.0803 0.8052
d-prime   2.3214     0.6510 0.7827 3.7069

Result of difference test:
Pearson X-square statistic = 7.5, df = 1, p-value: 0.003085
Alternative hypothesis: d-prime is greater than 0 

> 
> ## plot the distributions of sensory intensity:
> m1 <- discrim(10, 15, method = "twoAFC")
> plot(m1)
> 
> ## A similarity test where less than chance successes are obtained:
> discrim(20, 75, method = "triangle", pd0 = .2, test = "similarity")

Estimates for the triangle discrimination protocol with 20 correct
answers in 75 trials. One-sided p-value and 95 % two-sided confidence
intervals are based on the 'exact' binomial test. 

        Estimate Std. Error  Lower   Upper
pc        0.3333         NA 0.3333 0.38137
pd        0.0000         NA 0.0000 0.07206
d-prime   0.0000         NA 0.0000 0.73949

Result of similarity test:
'exact' binomial test:  p-value = 0.0003061 
Alternative hypothesis: d-prime is less than 1.287124 

> 
> 
> 
> 
> cleanEx()
> nameEx("discrimPwr")
> ### * discrimPwr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: discrimPwr
> ### Title: Sensory discrimination power analysis
> ### Aliases: discrimPwr d.primePwr
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Finding the power of a discrimination test with d-prime = 1,
> ## a sample of size 30 and a type I level of .05:
> pd <- coef(rescale(d.prime = 1, method = "twoAFC"))$pd
> discrimPwr(pd, sample.size = 30)
[1] 0.9172552
> d.primePwr(1, sample.size = 30, method = "twoAFC")
[1] 0.9172552
> ## Obtaining the equivalent normal approximation with and without
> ## continuity correction:
> discrimPwr(pd, sample.size = 30, statistic = "cont.normal")
[1] 0.8846648
> discrimPwr(pd, sample.size = 30, statistic = "normal")
[1] 0.921092
> 
> 
> ## A similarity example:
> discrimPwr(pdA = 0.1, pd0 = 0.2, sample.size = 100, pGuess = 1/3,
+            test = "similarity")
[1] 0.3068098
> 
> 
> 
> 
> cleanEx()
> nameEx("discrimR")
> ### * discrimR
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: discrimR
> ### Title: Replicated Thurstonian Model for discrimination analysis
> ### Aliases: discrimR
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Not run: 
> ##D freq <- c(10,8,10,9,8,9,9,1,10,10,8,2,6,7,6,7,6,4,5,5,3,3,9,9,5,5,8,8,9,9)
> ##D tmp <- data.frame(id = factor(1:30), n = rep(10, 30), freq = freq)
> ##D head(tmp)
> ##D str(tmp)
> ##D 
> ##D fm <- discrimR(cbind(freq, n - freq) ~ 1, tmp, cluster = id,
> ##D                     start = c(.5, .5), method = "twoAFC",
> ##D                     ranef = TRUE, zi = TRUE, hess = TRUE, 
> ##D                     control=list(trace=TRUE, REPORT=1))
> ##D 
> ##D names(fm)
> ##D fm[1:4]
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("discrimSS")
> ### * discrimSS
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: discrimSS
> ### Title: Sensory discrimination sample size calculation
> ### Aliases: discrimSS d.primeSS
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Finding the smallest necessary sample size:
> discrimSS(pdA = 0.5, pd0 = 0, target.power = 0.80, alpha = 0.05,
+    pGuess = 1/2, test = "difference", statistic = "exact")
[1] 23
> 
> ## Give identical results:
> pd <- coef(rescale(d.prime = 1, method = "twoAFC"))$pd
> discrimSS(pdA = pd, pd0 = 0, target.power = 0.90, alpha = 0.05,
+    pGuess = 1/2, test = "difference", statistic = "exact")
[1] 30
> d.primeSS(1, target.power = 0.90, method = "twoAFC")
[1] 30
> 
> ## A similarity example:
> discrimSS(pdA = 0.1, pd0 = 0.2, target.power = 0.80, alpha = 0.05,
+    pGuess = 1/2, test = "similarity", statistic = "exact")
[1] 604
> 
> 
> 
> 
> cleanEx()
> nameEx("discrimSim")
> ### * discrimSim
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: discrimSim
> ### Title: Simulates replicated difference tests
> ### Aliases: discrimSim
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Running simulations:
> discrimSim(sample.size = 10, replicates = 3, d.prime = 2,
+            method = "triangle", sd.indiv = 1)
 [1] 3 3 2 3 3 1 3 3 1 2
> 
> 
> 
> cleanEx()
> nameEx("duotrio")
> ### * duotrio
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: duotrio
> ### Title: Create duotrio binomial family
> ### Aliases: duotrio
> ### Keywords: models
> 
> ### ** Examples
> 
> xt <- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
> res <- glm(xt ~ 1, family = duotrio)
> summary(res)

Call:
glm(formula = xt ~ 1, family = duotrio)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)   1.5189     0.7159   2.122   0.0339 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0  on 0  degrees of freedom
Residual deviance: 0  on 0  degrees of freedom
AIC: 5.0807

Number of Fisher Scoring iterations: 3

> 
> ## Extended example plotting the profile likelihood
> ## data: 10 correct answers, 5 incorrect
> xt <- matrix(c(10, 5), ncol = 2)
> summary(res <- glm(xt ~ 1, family = duotrio))

Call:
glm(formula = xt ~ 1, family = duotrio)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)   1.5189     0.7159   2.122   0.0339 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0  on 0  degrees of freedom
Residual deviance: 0  on 0  degrees of freedom
AIC: 5.0807

Number of Fisher Scoring iterations: 3

> N <- 100
> dev <- double(N)
> delta <- seq(1e-4, 5, length = N)
> for(i in 1:N)
+   dev[i] <- glm(xt ~ -1 + offset(delta[i]),
+                 family = duotrio)$deviance
> plot(delta, exp(-dev/2), type = "l",
+      xlab = expression(delta),
+      ylab = "Normalized Profile Likelihood")
> ## Add Normal approximation:
> lines(delta, exp(-(delta - coef(res))^2 /
+                  (2 * vcov(res))), lty = 2)
> ## Add confidence limits:
> level <- c(0.95, 0.99)
> lim <- sapply(level, function(x)
+               exp(-qchisq(x, df=1)/2) )
> abline(h = lim, col = "grey")
> points(confint(res), rep(lim[1], 2), pch = 4)
Waiting for profiling to be done...
> 
> 
> 
> 
> cleanEx()
> nameEx("findcr")
> ### * findcr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findcr
> ### Title: Find the critical value of a one-tailed binomial test
> ### Aliases: findcr
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Find the critical value for a triangle test for the level 0.05 test
> ## with 25 subjects:
> findcr(sample.size = 25, , p0 = 1/3)
[1] 13
> 
> ## Similarity example:
> findcr(sample.size = 25, p0 = 1/3, pd0 = .2, test = "simil")
[1] 7
> 
> 
> 
> cleanEx()
> nameEx("plot.discrim")
> ### * plot.discrim
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.discrim
> ### Title: Plot function for discrim objects
> ### Aliases: plot.discrim
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Generate discrim objects to be plotted:
> fm1 <- discrim(10, 15, method = "threeAFC")
> fm2 <- discrim(10, 15, method = "triangle")
> par(mfrow=c(2,1)) ## Split plotting window in two
> ## Plot the distributions of sensory intensity for the two objects
> ## and increase the line width
> plot(fm1, lwd=2) 
> plot(fm2, lwd=2)
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("plot.samediff")
> ### * plot.samediff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.samediff
> ### Title: Plot function for samediff objects
> ### Aliases: plot.samediff
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Make same-diff object:
> sadi <- samediff(8, 5, 4, 9)
> ## Plot distributions of sensory intensity:
> plot(sadi)
> 
> 
> 
> cleanEx()
> nameEx("profile.discrim")
> ### * profile.discrim
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: profile.discrim
> ### Title: Profile likelihood and confidence interval methods for discrim
> ###   objects
> ### Aliases: profile.discrim plot.profile.discrim confint.discrim
> ### Keywords: models
> 
> ### ** Examples
> 
> ## 7 success out of 10 samples in a duo-trio experiment:
> (dd <- discrim(7, 10, method = "duotrio", statistic = "likelihood"))

Estimates for the duotrio discrimination protocol with 7 correct
answers in 10 trials. One-sided p-value and 95 % two-sided confidence
intervals are based on the likelihood root statistic. 

        Estimate Std. Error Lower  Upper
pc         0.700     0.1449   0.5 0.9154
pd         0.400     0.2898   0.0 0.8309
d-prime    1.715     0.8598   0.0 3.4656

Result of difference test:
Likelihood Root statistic = 1.282832, p-value: 0.09978
Alternative hypothesis: d-prime is greater than 0 

> confint(dd)
        Lower     Upper
pc        0.5 0.9154321
pd        0.0 0.8308642
d-prime   0.0 3.4656468
attr(,"method")
[1] "duotrio"
attr(,"conf.level")
[1] 0.95
attr(,"statistic")
[1] "likelihood"
> plot(profile(dd))
> points(confint(dd)[3,], rep(.1465, 2), pch = 3, cex = 2, lwd=2)
> 
> 
> 
> 
> cleanEx()
> nameEx("profile.samediff")
> ### * profile.samediff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: profile.samediff
> ### Title: Profile likelihood methods for samediff objects.
> ### Aliases: profile.samediff plot.profile.samediff confint.samediff
> ### Keywords: models
> 
> ### ** Examples
> 
> # data: 8 of the same samples were judged to be same
> #       5 of the same samples were judged to be different
> #       4 of the different samples were judged to be same
> #       9 of the different samples were judged to be different
> 
> sadi <- samediff(8, 5, 4, 9)
> confint(sadi)
                Lower    Upper
0.95% tau   0.6378682 1.992460
0.95% delta 0.0000000 3.206213
> plot(profile(sadi))
> 
> 
> 
> 
> cleanEx()
> nameEx("rescale")
> ### * rescale
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rescale
> ### Title: Transform or rescale between pc, pd and d-prime for sensory
> ###   discrimination protocols
> ### Aliases: rescale psyfun psyinv psyderiv pc2pd pd2pc
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## suppose 15 out of 20 are observed in a duo-trio experiment, then
> ## the estimated probability of correct a answer is
> (pc <- 15/20)
[1] 0.75
> ## The standard error of this estimate is
> (se.pc <- sqrt(pc * (1 - pc) / 20))
[1] 0.09682458
> ## The corresponding estimate of proportion of discriminators (pd) and
> ## d-prime with associated standard errors are:
> rescale(pc = pc, std.err = se.pc, method = "duotrio")

Estimates for the duotrio protocol:
    pc  pd  d.prime
1 0.75 0.5 2.020013

Standard errors:
          pc        pd   d.prime
1 0.09682458 0.1936492 0.6119759
> 
> ## Can also do
> rescale(pd = c(.6,.7), std.err = c(.2, NA))

Estimates for the duotrio protocol:
    pc  pd  d.prime
1 0.80 0.6 2.354862
2 0.85 0.7 2.749327

Standard errors:
   pc  pd   d.prime
1 0.1 0.2 0.7165361
2  NA  NA        NA
> psyfun(2, method = "triangle")
[1] 0.6048069
> psyinv(0.8, method = "twoAFC")
[1] 1.190232
> psyderiv(2, method = "duotrio")
[1] 0.1591337
> pc2pd(0.7, 1/2)
[1] 0.4
> pd2pc(0.3, 1/3)
[1] 0.5333333
> 
> 
> 
> 
> cleanEx()
> nameEx("samediff")
> ### * samediff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: samediff
> ### Title: Computation of tau and dprime for same different test
> ### Aliases: samediff
> ### Keywords: models
> 
> ### ** Examples
> 
> # data: 8 of the same samples were judged to be same
> #       5 of the same samples were judged to be different
> #       4 of the different samples were judged to be same
> #       9 of the different samples were judged to be different
> 
> samediff(8, 5, 4, 9)

Call:
samediff(nsamesame = 8, ndiffsame = 5, nsamediff = 4, ndiffdiff = 9)

Coefficients:
  tau  delta  
1.230  1.885  

> 
> 
> 
> cleanEx()
> nameEx("samediffPwr")
> ### * samediffPwr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: samediffPwr
> ### Title: Power Analysis for Same-different Experiments
> ### Aliases: samediffPwr
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Finding the power of a discrimination test with a sensory delta of 2
> ## (alternative hypothesis) versus a null hypothesis of delta = 0 with
> ## a sample of size 2 x 10 and a type I level of .05. n should be higher
> ## for a reasonable precision:
> 
> samediffPwr(n = 100, tau = 1, delta = 2, Ns = 10, Nd = 10)
[1] 0.4
> 
> 
> 
> 
> cleanEx()
> nameEx("samediffSim")
> ### * samediffSim
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: samediffSim
> ### Title: Simulates data from a samediff test
> ### Aliases: samediffSim
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Running simulations:
> samediffSim(n = 10, tau = 1, delta = 1, Ns = 10, Nd = 10)
      ss ds sd dd
 [1,]  6  4  3  7
 [2,]  6  4  3  7
 [3,]  5  5  5  5
 [4,]  3  7  4  6
 [5,]  7  3  5  5
 [6,]  3  7  4  6
 [7,]  3  7  5  5
 [8,]  5  5  8  2
 [9,]  5  5  4  6
[10,]  8  2  5  5
> 
> 
> 
> 
> cleanEx()
> nameEx("summary.samediff")
> ### * summary.samediff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.samediff
> ### Title: Summary method for samediff objects.
> ### Aliases: summary.samediff
> ### Keywords: models
> 
> ### ** Examples
> 
> # data: 8 of the same samples were judged to be same
> #       5 of the same samples were judged to be different
> #       4 of the different samples were judged to be same
> #       9 of the different samples were judged to be different
> 
> sadi <- samediff(8, 5, 4, 9)
> summary(sadi)

Call:
samediff(nsamesame = 8, ndiffsame = 5, nsamediff = 4, ndiffdiff = 9)

Coefficients
      Estimate Std. Error  Lower  Upper P-value    
tau     1.2296     0.3490 0.6379 1.9925  <2e-16 ***
delta   1.8850     0.7035 0.0000 3.2062  0.0563 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log Likelihood: -16.6858 	AIC: 37.3715 
> summary(sadi, FALSE)

Call:
samediff(nsamesame = 8, ndiffsame = 5, nsamediff = 4, ndiffdiff = 9)

Coefficients
      Estimate Std. Error  Lower  Upper  P-value    
tau     1.2296     0.3490 0.5455 1.9136 0.000213 ***
delta   1.8850     0.7035 0.5061 3.2639 0.003688 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log Likelihood: -16.6858 	AIC: 37.3715 
> 
> 
> 
> 
> cleanEx()
> nameEx("tetrad")
> ### * tetrad
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tetrad
> ### Title: Create tetrad binomial family
> ### Aliases: tetrad
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> xt <- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
> res <- glm(xt ~ 1, family = tetrad)
> summary(res)

Call:
glm(formula = xt ~ 1, family = tetrad)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.5878     0.4193   3.787 0.000153 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0  on 0  degrees of freedom
Residual deviance: 0  on 0  degrees of freedom
AIC: 5.0807

Number of Fisher Scoring iterations: 3

> 
> ## Extended example plotting the profile likelihood
> ## data: 10 correct answers, 9 incorrect
> xt <- matrix(c(10, 9), ncol = 2)
> summary(res <- glm(xt ~ 1, family = tetrad))

Call:
glm(formula = xt ~ 1, family = tetrad)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)   1.1142     0.3947   2.823  0.00476 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance:  0.0000e+00  on 0  degrees of freedom
Residual deviance: -1.7764e-15  on 0  degrees of freedom
AIC: 5.4196

Number of Fisher Scoring iterations: 2

> N <- 100
> dev <- double(N)
> delta <- seq(1e-4, 3, length = N)
> for(i in 1:N)
+   dev[i] <- glm(xt ~ -1 + offset(delta[i]),
+                 family = tetrad)$deviance
> plot(delta, exp(-dev/2), type = "l",
+      xlab = expression(delta),
+      ylab = "Normalized Profile Likelihood")
> ## Add Normal approximation:
> lines(delta, exp(-(delta - coef(res))^2 /
+                  (2 * vcov(res))), lty = 2)
> ## Add confidence limits:
> level <- c(0.95, 0.99)
> lim <- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
> abline(h = lim, col = "grey")
> 
> 
> 
> 
> cleanEx()
> nameEx("threeAFC")
> ### * threeAFC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: threeAFC
> ### Title: Create 3-AFC binomial family
> ### Aliases: threeAFC
> ### Keywords: models
> 
> ### ** Examples
> 
> xt <- matrix(c(10, 5), ncol = 2) # data: 10 correct answers, 5 incorrect
> res <- glm(xt ~ 1, family=threeAFC)
> summary(res)

Call:
glm(formula = xt ~ 1, family = threeAFC)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)   1.1159     0.4359    2.56   0.0105 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0  on 0  degrees of freedom
Residual deviance: 0  on 0  degrees of freedom
AIC: 5.0807

Number of Fisher Scoring iterations: 3

> 
> ## Extended example plotting the profile likelihood
> ## data: 10 correct answers, 5 incorrect
> xt <- matrix(c(10, 2), ncol = 2)
> summary(res <- glm(xt ~ 1, family = threeAFC))#, etastart = etastart))

Call:
glm(formula = xt ~ 1, family = threeAFC)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)   1.8173     0.5648   3.218  0.00129 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0.0000e+00  on 0  degrees of freedom
Residual deviance: 1.7763e-15  on 0  degrees of freedom
AIC: 4.4342

Number of Fisher Scoring iterations: 3

> N <- 100
> dev <- double(N)
> level <- c(0.95, 0.99)
> delta <- seq(1e-4, 5, length = N)
> for(i in 1:N)
+   dev[i] <- glm(xt ~ -1 + offset(delta[i]),
+                 family = threeAFC)$deviance
> plot(delta, exp(-dev/2), type = "l",
+      xlab = expression(delta),
+      ylab = "Normalized Profile Likelihood")
> ## Add Normal approximation:
> lines(delta, exp(-(delta - coef(res))^2 /
+                  (2 * vcov(res))), lty = 2)
> ## Add confidence limits:
> lim <- sapply(level, function(x)
+               exp(-qchisq(x, df=1)/2) )
> abline(h = lim, col = "grey")
> 
> 
> 
> cleanEx()
> nameEx("triangle")
> ### * triangle
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: triangle
> ### Title: Create triangle binomial family
> ### Aliases: triangle
> ### Keywords: models
> 
> ### ** Examples
> 
> xt <- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
> res <- glm(xt ~ 1, family = triangle)
> summary(res)

Call:
glm(formula = xt ~ 1, family = triangle)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    2.321      0.651   3.566 0.000363 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0  on 0  degrees of freedom
Residual deviance: 0  on 0  degrees of freedom
AIC: 5.0807

Number of Fisher Scoring iterations: 3

> 
> ## Extended example plotting the profile likelihood
> ## data: 10 correct answers, 9 incorrect
> xt <- matrix(c(10, 9), ncol = 2)
> summary(res <- glm(xt ~ 1, family = triangle))

Call:
glm(formula = xt ~ 1, family = triangle)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)   1.6025     0.5864   2.733  0.00628 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0.0000e+00  on 0  degrees of freedom
Residual deviance: 1.7764e-15  on 0  degrees of freedom
AIC: 5.4196

Number of Fisher Scoring iterations: 2

> N <- 100
> dev <- double(N)
> delta <- seq(1e-4, 3, length = N)
> for(i in 1:N)
+   dev[i] <- glm(xt ~ -1 + offset(delta[i]),
+                 family = triangle)$deviance
> plot(delta, exp(-dev/2), type = "l",
+      xlab = expression(delta),
+      ylab = "Normalized Profile Likelihood")
> ## Add Normal approximation:
> lines(delta, exp(-(delta - coef(res))^2 /
+                  (2 * vcov(res))), lty = 2)
> ## Add confidence limits:
> level <- c(0.95, 0.99)
> lim <- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
> abline(h = lim, col = "grey")
> 
> 
> 
> 
> cleanEx()
> nameEx("twoAC")
> ### * twoAC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: twoAC
> ### Title: 2-AC Discrimination and Preference Protocol
> ### Aliases: twoAC print.twoAC
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Simple:
> fit <- twoAC(c(2,2,6))
> fit
Results for the 2-AC protocol with data c(2, 2, 6):
        Estimate Std. Error
tau       0.4160     0.2674
d.prime   0.7743     0.5417

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
         Lower Upper
d.prime -0.271 1.859

Significance test:
 Likelihood root statistic = 1.446718 p-value = 0.14798 
 Alternative hypothesis: d-prime is different from 0 
> 
> ## Typical discrimination-difference test: 
> (fit <- twoAC(data = c(2, 5, 8), d.prime0 = 0, alternative = "greater"))
Results for the 2-AC protocol with data c(2, 5, 8):
        Estimate Std. Error
tau       0.7263     0.2832
d.prime   0.8446     0.4370

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
           Lower Upper
d.prime 0.001453 1.719

Significance test:
 Likelihood root statistic = 1.963389 p-value = 0.024801 
 Alternative hypothesis: d-prime is greater than 0 
> 
> ## Typical discrimination-similarity test: 
> (fit <- twoAC(data = c(15, 15, 20), d.prime0 = .5, alternative = "less"))
Results for the 2-AC protocol with data c(15, 15, 20):
        Estimate Std. Error
tau       0.5500     0.1248
d.prime   0.1917     0.2265

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
          Lower  Upper
d.prime -0.2518 0.6366

Significance test:
 Likelihood root statistic = -1.359323 p-value = 0.087022 
 Alternative hypothesis: d-prime is less than 0.5 
> 
> ## Typical preference-difference test:
> (fit <- twoAC(data = c(3, 5, 12), d.prime0 = 0,
+               alternative = "two.sided"))
Results for the 2-AC protocol with data c(3, 5, 12):
        Estimate Std. Error
tau       0.5537     0.2211
d.prime   0.9120     0.3857

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
         Lower Upper
d.prime 0.1666 1.681

Significance test:
 Likelihood root statistic = 2.40465 p-value = 0.016188 
 Alternative hypothesis: d-prime is different from 0 
> 
> ## Typical preference (non-)inferiority test:
> (fit <- twoAC(data = c(3, 5, 12), d.prime0 = 0,
+               alternative = "greater"))
Results for the 2-AC protocol with data c(3, 5, 12):
        Estimate Std. Error
tau       0.5537     0.2211
d.prime   0.9120     0.3857

Two-sided 95% confidence interval for d-prime based on the
likelihood root statistic:
         Lower Upper
d.prime 0.1666 1.681

Significance test:
 Likelihood root statistic = 2.40465 p-value = 0.008094 
 Alternative hypothesis: d-prime is greater than 0 
> 
> ## For preference equivalence tests (two-sided) use CI with alpha/2:
> ## declare equivalence at the 5% level if 90% CI does not contain,
> ## e.g, -1 or 1: 
> (fit <- twoAC(data = c(15, 10, 10), d.prime0 = 0, conf.level = .90))
Results for the 2-AC protocol with data c(15, 10, 10):
        Estimate Std. Error
tau       0.5275     0.1474
d.prime  -0.2729     0.2723

Two-sided 90% confidence interval for d-prime based on the
likelihood root statistic:
          Lower  Upper
d.prime -0.7221 0.1742

Significance test:
 Likelihood root statistic = -1.003382 p-value = 0.31568 
 Alternative hypothesis: d-prime is different from 0 
> 
> ## The var-cov matrix and standard errors of the parameters are not
> ## defined in all situations. If standard errors are not
> ## defined, then confidence intervals are not provided directly:
> (fit <- twoAC(c(5, 0, 15)))
Results for the 2-AC protocol with data c(5, 0, 15):
        Estimate Std. Error
tau       0.0000         NA
d.prime   0.9539         NA

Use profile and confint methods to get confidence interval

Significance test:
 Likelihood root statistic = 2.287737 p-value = 0.022153 
 Alternative hypothesis: d-prime is different from 0 
> ## We may use profile and confint methods to get confidence intervals
> ## never the less: 
> pr <- profile(fit, range = c(-1, 3))
> confint(pr)
            2.5 %   97.5 %
d.prime 0.1333637 1.830032
> plot(pr)
> 
> 
> 
> 
> cleanEx()
> nameEx("twoACpwr")
> ### * twoACpwr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: twoACpwr
> ### Title: Exact Power Computation for the 2-AC Discrimination Protocol
> ### Aliases: twoACpwr
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Exact power: 
> twoACpwr(tau = .5, d.prime = .7, size = 50, tol = 0)
      power actual.alpha samples discarded kept    p.1    p.2    p.3
1 0.8645723   0.04960103    1326         0 1326 0.1981 0.2457 0.5562
> 
> ## Power exact to a reasonable number of digits
> twoACpwr(tau = .5, d.prime = .7, size = 50, tol = 1e-5)
      power actual.alpha samples discarded kept    p.1    p.2    p.3
1 0.8645687   0.04959461    1326       795  531 0.1981 0.2457 0.5562
> 
> ## Power for a similarity test in a discrimination setting where the
> ## true parameter values are expected to be tau = 0.4 and true d.prime
> ## = .5, while we want to show that d.prime < 1, i.e., under the null
> ## hypothesis d.prime = 1:
> twoACpwr(tau = .4, d.prime = .5, size = 100, d.prime0 = 1, tol = 1e-5, 
+          alternative = "less")
      power actual.alpha samples discarded kept    p.1    p.2    p.3
1 0.8977633   0.04930859    5151      3977 1174 0.2623 0.2096 0.5282
> 
> ## Power for a difference test in a preference setting where the true
> ## parameter values are expected to be tau = 0.4 and d.prime = -0.5,
> ## while we want to show that d.prime is different from zero:
> twoACpwr(tau = 0.4, d.prime = -0.5, size = 100, d.prime0 = 0, tol = 1e-5, 
+          alternative = "two.sided")
     power actual.alpha samples discarded kept    p.1    p.2    p.3
1 0.863213   0.04957598    5151      3977 1174 0.5282 0.2096 0.2623
> 
> 
> 
> 
> cleanEx()
> nameEx("twoAFC")
> ### * twoAFC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: twoAFC
> ### Title: Create 2-AFC binomial family
> ### Aliases: twoAFC
> ### Keywords: models
> 
> ### ** Examples
> 
> xt <- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
> res <- glm(xt ~ 1, family = twoAFC)
> summary(res)

Call:
glm(formula = xt ~ 1, family = twoAFC)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.6091     0.4734   1.287    0.198

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 0  on 0  degrees of freedom
Residual deviance: 0  on 0  degrees of freedom
AIC: 5.0807

Number of Fisher Scoring iterations: 3

> 
> ## Extended example plotting the profile likelihood
> ## data: 10 correct and 8 incorrect:
> xt <- matrix(c(10, 8), ncol = 2)
> summary(res <- glm(xt ~ 1, family = twoAFC))

Call:
glm(formula = xt ~ 1, family = twoAFC)

Deviance Residuals: 
[1]  0

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.1976     0.4193   0.471    0.637

(Dispersion parameter for binomial family taken to be 1)

    Null deviance:  0.0000e+00  on 0  degrees of freedom
Residual deviance: -1.0249e-23  on 0  degrees of freedom
AIC: 5.3578

Number of Fisher Scoring iterations: 2

> N <- 100
> dev <- double(N)
> level <- c(0.95, 0.99)
> delta <- seq(1e-4, 3, length = N)
> for(i in 1:N)
+   dev[i] <- glm(xt ~ -1 + offset(delta[i]),
+                 family = twoAFC)$deviance
> plot(delta, exp(-dev/2), type = "l",
+      xlab = expression(delta),
+      ylab = "Normalized Profile Likelihood")
> ## Add Normal approximation:
> lines(delta, exp(-(delta - coef(res))^2 /
+                  (2 * vcov(res))), lty = 2)
> ## Add confidence limits:
> lim <- sapply(level, function(x)
+               exp(-qchisq(x, df=1)/2) )
> abline(h = lim, col = "grey")
> 
> 
> 
> ### * <FOOTER>
> ###
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  5.799 0.108 6.007 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
